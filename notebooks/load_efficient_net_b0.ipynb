{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/Volumes/SD Card/cleaned'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from keras.engine.functional import Functional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model:Functional = tf.keras.models.load_model(\"../models/efficient_net_b0-17:06:20.805646.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Construct Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosonant_path = '/Volumes/SD Card/cleaned_hand'\n",
    "root = os.listdir(cosonant_path)[20]\n",
    "consonant = f'{cosonant_path}/{root}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Volumes/SD Card/cleaned_hand/ha/176.jpg'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_img_path = f'{consonant}/{os.listdir(consonant)[1]}'\n",
    "sample_img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = tf.image.resize(image, size=(224, 224))\n",
    "    image = tf.cast(image, dtype=tf.float32)\n",
    "    return image\n",
    "\n",
    "image = resize_image(sample_img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Prediction\n",
    "TODO: Find meaning of this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x15f417d00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "7/7 [==============================] - 2s 19ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00012861, 0.00012822, 0.00014009, ..., 0.00012642, 0.00012787,\n",
       "        0.00012716],\n",
       "       [0.00012807, 0.00012757, 0.00013984, ..., 0.00012624, 0.00012793,\n",
       "        0.00012731],\n",
       "       [0.00012849, 0.00012781, 0.00014   , ..., 0.00012626, 0.00012815,\n",
       "        0.0001267 ],\n",
       "       ...,\n",
       "       [0.00012822, 0.00012813, 0.00014048, ..., 0.00012646, 0.00012833,\n",
       "        0.00012664],\n",
       "       [0.00012834, 0.00012822, 0.00014046, ..., 0.0001263 , 0.00012799,\n",
       "        0.00012764],\n",
       "       [0.00012828, 0.00012801, 0.00014028, ..., 0.00012629, 0.00012758,\n",
       "        0.000127  ]], dtype=float32)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction = model.predict(np.array([image])) # if below code not work\n",
    "prediction = model.predict(image)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# argmax = tf.argmax(prediction)\n",
    "# argmax\n",
    "# e in prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joined = prediction[0]\n",
    "# joined[np.where(joined == np.max(joined))] = 1\n",
    "# joined[np.where(joined != np.max(joined))] = 0\n",
    "# joined = list(map(int, joined))\n",
    "# joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zipped = zip(joined, labels)\n",
    "# for i in list(zipped):\n",
    "#     if i[0] == 1:\n",
    "#         print(i[1])\n",
    "# list(zipped)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit ('3.10.0')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8d83d870ee499a7f35a03e9e5e6e84ce02f1ac8f9e1937d0a54b919ea69e0ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
